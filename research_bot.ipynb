{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP63OKcvefxXbOxAuPaA8FH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buddypia/openai-agents-sdk-colab/blob/master/research_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siY4xKhuRQey",
        "outputId": "e52238d9-d2be-4d1f-e887-6fc89b0ace8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.0.14-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting mcp<2,>=1.6.0 (from openai-agents)\n",
            "  Downloading mcp-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: openai>=1.76.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (1.76.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.11.3)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.32.3)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (4.13.2)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.6.0->openai-agents) (4.9.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.6.0->openai-agents) (0.28.1)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting python-multipart>=0.0.9 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading sse_starlette-2.3.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting starlette>=0.27 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting uvicorn>=0.23.1 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp<2,>=1.6.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.6.0->openai-agents) (0.16.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp<2,>=1.6.0->openai-agents) (8.1.8)\n",
            "Downloading openai_agents-0.0.14-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.7.0-py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading sse_starlette-2.3.3-py3-none-any.whl (10 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: uvicorn, types-requests, python-multipart, python-dotenv, httpx-sse, colorama, starlette, griffe, sse-starlette, pydantic-settings, mcp, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.7.3 httpx-sse-0.4.0 mcp-1.7.0 openai-agents-0.0.14 pydantic-settings-2.9.1 python-dotenv-1.1.0 python-multipart-0.0.20 sse-starlette-2.3.3 starlette-0.46.2 types-requests-2.32.0.20250328 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# ColabのシークレットからOpenAIのAPIキーを取得\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# OpenAIエージェントにAPIキーを設定\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "gIllnimiRpwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "from agents import Agent\n",
        "\n",
        "PROMPT = (\n",
        "    \"あなたは役に立つリサーチアシスタントです。クエリが与えられた場合、\"\n",
        "    \"そのクエリに最もよく答えるために実行する一連のウェブ検索を考案してください。\"\n",
        "    \"検索する用語を5から20個の間で出力してください。\"\n",
        ")\n",
        "\n",
        "# WebSearchItemモデル：個々のウェブ検索アイテムを定義\n",
        "class WebSearchItem(BaseModel):\n",
        "    reason: str\n",
        "    \"\"\"この検索がクエリにとって重要である理由についてのあなたの推論。\"\"\"\n",
        "\n",
        "    query: str\n",
        "    \"\"\"ウェブ検索に使用する検索語。\"\"\"\n",
        "\n",
        "\n",
        "class WebSearchPlan(BaseModel):\n",
        "    searches: list[WebSearchItem]\n",
        "    \"\"\"クエリに最もよく答えるために実行するウェブ検索のリスト。\"\"\"\n",
        "\n",
        "# プランナーエージェントを定義\n",
        "planner_agent = Agent(\n",
        "    name=\"PlannerAgent\",\n",
        "    instructions=PROMPT,\n",
        "    model=\"gpt-4o\",\n",
        "    output_type=WebSearchPlan,\n",
        ")"
      ],
      "metadata": {
        "id": "wYGKFhHVRyo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, WebSearchTool\n",
        "from agents.model_settings import ModelSettings\n",
        "\n",
        "INSTRUCTIONS = (\n",
        "    \"あなたはリサーチアシスタントです。検索語が与えられたら、その語でウェブを検索し、\"\n",
        "    \"結果の簡潔な要約を作成します。要約は2〜3段落、300語未満でなければなりません。\"\n",
        "    \"主要なポイントを捉えてください。簡潔に書き、完全な文や正しい文法は不要です。\"\n",
        "    \"これはレポートを作成する人が利用するため、本質を捉え、冗長な部分を無視することが不可欠です。\"\n",
        "    \"要約自体以外の追加のコメントは含めないでください。\"\n",
        ")\n",
        "\n",
        "# サーチエージェントを定義\n",
        "search_agent = Agent(\n",
        "    name=\"Search agent\",\n",
        "    instructions=INSTRUCTIONS,\n",
        "    tools=[WebSearchTool()],\n",
        "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
        ")"
      ],
      "metadata": {
        "id": "kvrlNse8TJ4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "from agents import Agent\n",
        "\n",
        "PROMPT = (\n",
        "    \"あなたは、ある調査クエリに対する一貫性のあるレポートを作成する任務を負った、シニアリサーチャーです。\\n\"\n",
        "    \"元のクエリと、リサーチアシスタントが行ったいくつかの初期調査が提供されます。\\n\"\n",
        "    \"まず、レポートの構造と流れを記述するレポートのアウトラインを作成する必要があります。\\n\"\n",
        "    \"次に、レポートを生成し、それを最終的な出力として返します。\\n\"\n",
        "    \"最終的な出力はマークダウン形式である必要があり、長く詳細なものにする必要があります。\\n\"\n",
        "    \"コンテンツは5〜10ページ、少なくとも1000語を目指してください。\"\n",
        ")\n",
        "\n",
        "class ReportData(BaseModel):\n",
        "    short_summary: str\n",
        "    \"\"\"調査結果の短い（2〜3文の）要約。\"\"\"\n",
        "\n",
        "    markdown_report: str\n",
        "    \"\"\"最終レポート\"\"\"\n",
        "\n",
        "    follow_up_questions: list[str]\n",
        "    \"\"\"さらなる調査のための推奨トピック\"\"\"\n",
        "\n",
        "# ライターエージェントを定義\n",
        "writer_agent = Agent(\n",
        "    name=\"WriterAgent\",\n",
        "    instructions=PROMPT,\n",
        "    model=\"o3-mini\",\n",
        "    output_type=ReportData,\n",
        ")"
      ],
      "metadata": {
        "id": "nTJw3zMbTaDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import time\n",
        "\n",
        "from agents import Runner, custom_span, gen_trace_id, trace\n",
        "\n",
        "class ResearchManager:\n",
        "  async def run(self, query: str) -> None:\n",
        "      # 検索計画を立てる\n",
        "      search_plan = await self._plan_searches(query)\n",
        "      # 検索を実行する\n",
        "      search_results = await self._perform_searches(search_plan)\n",
        "      # レポートを作成する\n",
        "      report = await self._write_report(query, search_results)\n",
        "\n",
        "      # 最終レポート（短い要約）\n",
        "      final_report = f\"レポート要約\\n\\n{report.short_summary}\"\n",
        "\n",
        "      print(\"\\n\\n=====レポート=====\\n\\n\")\n",
        "      print(f\"レポート: {report.markdown_report}\")\n",
        "      print(\"\\n\\n=====追加質問=====\\n\\n\")\n",
        "      follow_up_questions = \"\\n\".join(report.follow_up_questions)\n",
        "      print(f\"追加質問: {follow_up_questions}\")\n",
        "\n",
        "  async def _plan_searches(self, query: str) -> WebSearchPlan:\n",
        "    # プランナーエージェントを実行して検索計画を取得\n",
        "    result = await Runner.run(\n",
        "      planner_agent,\n",
        "      f\"クエリ: {query}\", # ユーザーの元のクエリ\n",
        "    )\n",
        "\n",
        "    # 結果をWebSearchPlanオブジェクトとして返す\n",
        "    return result.final_output_as(WebSearchPlan)\n",
        "\n",
        "  async def _perform_searches(self, search_plan: WebSearchPlan) -> list[str]:\n",
        "      # \"ウェブ検索\" という名前でカスタムスパンを開始\n",
        "      with custom_span(\"ウェブ検索\"):\n",
        "          num_completed = 0 # 完了した検索タスクの数\n",
        "          # 検索計画内の各項目に対して非同期検索タスクを作成\n",
        "          tasks = [asyncio.create_task(self._search(item)) for item in search_plan.searches]\n",
        "          results = [] # 検索結果を格納するリスト\n",
        "          # 完了したタスクから順に結果を処理\n",
        "          for task in asyncio.as_completed(tasks):\n",
        "              result = await task # タスクの結果を取得\n",
        "              if result is not None: # 結果がNoneでない場合のみ追加\n",
        "                  results.append(result)\n",
        "              num_completed += 1 # 完了数をインクリメント\n",
        "          return results # 検索結果のリストを返す\n",
        "\n",
        "  async def _search(self, item: WebSearchItem) -> str | None:\n",
        "      # 検索エージェントへの入力を作成\n",
        "      input = f\"検索語: {item.query}\\n検索理由: {item.reason}\"\n",
        "      try:\n",
        "          # 検索エージェントを実行\n",
        "          result = await Runner.run(\n",
        "              search_agent,\n",
        "              input,\n",
        "          )\n",
        "          # 結果を文字列として返す\n",
        "          return str(result.final_output)\n",
        "      except Exception:\n",
        "          # エラーが発生した場合はNoneを返す\n",
        "          return None\n",
        "\n",
        "  async def _write_report(self, query: str, search_results: list[str]) -> ReportData:\n",
        "      # ライターエージェントへの入力を作成\n",
        "      input = f\"元のクエリ: {query}\\n要約された検索結果: {search_results}\"\n",
        "      # ライターエージェントをストリームモードで実行\n",
        "      result = await Runner.run(\n",
        "          writer_agent,\n",
        "          input,\n",
        "      )\n",
        "\n",
        "      # 最終的な結果をReportDataオブジェクトとして返す\n",
        "      return result.final_output_as(ReportData)"
      ],
      "metadata": {
        "id": "keRxRA09UFTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"サイバーエージェントのAI事業本部の業務効率化のポイントについて\""
      ],
      "metadata": {
        "id": "47UFI0ihW3lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await ResearchManager().run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T793RZNrT9tK",
        "outputId": "7107a452-9a5b-45a0-b10e-2f5638674d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:openai.agents:No active trace. Make sure to start a trace with `trace()` firstReturning NoOpSpan.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=====レポート=====\n",
            "\n",
            "\n",
            "レポート: # サイバーエージェントのAI事業本部における業務効率化のポイントに関する詳細レポート\n",
            "\n",
            "本レポートでは、サイバーエージェントのAI事業本部がどのようにして業務効率化を推進しているのか、そしてその背後にある技術、組織戦略、課題、そして未来への展望について検証していきます。レポートは以下のセクションに分かれており、各セクションでは関連する取り組み、事例、技術背景について詳細に解説します。\n",
            "\n",
            "---\n",
            "\n",
            "## 1. はじめに\n",
            "\n",
            "サイバーエージェントは1998年の設立以来、デジタル広告、メディア、エンターテインメント分野で革新的なビジネスモデルを展開してきました。その中でも、2019年に発足したAI事業本部は、広告配信技術の革新や新規事業の創出を目的に設立され、AI技術とデジタルトランスフォーメーション（DX）を強力に推進しています。このレポートでは、業務効率化の観点から、同事業本部がどのようなツールや戦略を採用しているのか、またその取り組みがどのようにして企業全体の生産性向上に寄与しているのかを明らかにします。\n",
            "\n",
            "\n",
            "## 2. サイバーエージェントのAI事業本部の概要\n",
            "\n",
            "### 2.1 組織構造と役割\n",
            "\n",
            "サイバーエージェントのAI事業本部は、以下の主要な組織で構成されています：\n",
            "\n",
            "- **AI本部:** 高度なAIプロダクトの開発と提供を担い、広告配信の予測モデルやクリエイティブ制作におけるAI技術を推進。\n",
            "- **DX本部:** 小売、医療、デジタルガバメントなど、さまざまな業界におけるデジタル変革（DX）を支援。\n",
            "- **D2C本部:** 自社ブランドの創出と運営を担当し、AI技術を活用した市場分析および販売戦略を展開。\n",
            "- **Data Science Center:** データサイエンスの専門チームとして、各サービスの品質・精度向上を実現。\n",
            "- **AI Lab:** 機械学習、自然言語処理、コンピュータビジョンなど、多様なAI分野の研究開発の最前線として、大学や研究機関との連携を推進。\n",
            "\n",
            "### 2.2 歴史と背景\n",
            "\n",
            "2019年のAI事業本部の設立背景には、デジタル広告業界におけるAI技術の重要性の高まりと、新たなビジネスモデルの創出が求められたことがあります。近年、生成AIの登場により、社内外の業務効率化の可能性が劇的に広がっており、同社は最新技術を積極的に導入することで、市場環境に適応しています。\n",
            "\n",
            "\n",
            "## 3. AIツールと技術の活用\n",
            "\n",
            "### 3.1 一般的なAIツール\n",
            "\n",
            "業務効率化のために、サイバーエージェントだけでなく多くの企業が組み合わせ利用している主要なAIツールには、以下のものがあります：\n",
            "\n",
            "- **文章作成・編集系ツール:** \n",
            "  - *ChatGPT:* 企業内の文書作成、メール返信、翻訳など多岐にわたるタスクで活用。\n",
            "  - *Notion AI:* ドキュメント管理とタスク管理が効率化される。\n",
            "  - *Jasper AI:* マーケティング分野において、ブログ記事や広告コピーの生成を支援。\n",
            "\n",
            "- **データ分析・管理系ツール:** \n",
            "  - *DataRobot, H2O.ai:* 自動機械学習プラットフォームとして、データ処理と予測モデル作成の自動化に貢献。\n",
            "\n",
            "- **業務自動化ツール:** \n",
            "  - *UiPath:* RPAツールとして、ルーチンな作業や定型業務の自動化に優れた効果を発揮。\n",
            "  - *Microsoft Power Automate:* 業務フローの自動化において、Office製品とのシームレスな統合が特徴。\n",
            "\n",
            "- **プロジェクト管理・タスク管理系ツール:** \n",
            "  - *Asanaの「AIチームメイト」:* タスク割り当てや進捗管理をAIがサポートし、チームの生産性向上に寄与。\n",
            "\n",
            "### 3.2 サイバーエージェント独自の技術とプロダクト\n",
            "\n",
            "サイバーエージェントでは、外部ツールの活用に加えて、生成AIを中心とした自社開発プロダクトを展開しています。たとえば：\n",
            "\n",
            "- **極予測AI、極予測TD:** 広告効果や適切な広告文の自動生成を実現し、マーケティング施策の高度化を促進。\n",
            "- **AI Messenger for Voice:** 電話対応の自動化によって、顧客サービスの迅速化と効率化を実現。\n",
            "- **OpenCALM:** 日本語に特化した大規模言語モデルとして、業務文書やマーケティングコンテンツの作成に寄与。\n",
            "\n",
            "また、生成AIを活用した業務改革支援プラットフォーム「AI Worker」および「AI Worker Studio」は、様々な業務プロセスの効率化を図るために設計され、最新技術スタック（TypeScript、Kubernetes、Terraformなど）を用いて構築されています。\n",
            "\n",
            "\n",
            "## 4. 業務効率化の実践事例\n",
            "\n",
            "### 4.1 社内効率化イニシアチブ\n",
            "\n",
            "2023年10月に設立された「AIオペレーション室」は、全社員の生成AIリテラシー向上と業務効率化を目的とした取り組みです。この組織は、社員向けeラーニングプログラムの提供、内製のAI活用コンテスト、そして専属AIアシスタントの導入など、実際の業務効率化に直結する複数の施策を展開しています。例えば、広告オペレーションの効率化を図る「シーエーアシスタント」は、各担当者に個別のAIアシスタントを提供し、月間2.4万時間の労働削減を目指しています。\n",
            "\n",
            "### 4.2 社内外コンペティションとイノベーションの促進\n",
            "\n",
            "生成AIの活用アイデアを募る社内コンテストが開催され、約2200件の応募アイデアが集まりました。グランプリに選ばれたツールは、強化学習を利用したスケジュール自動調整システムで、月間6万時間の労働時間削減が見込まれています。これにより、組織全体が生成AIをどのように活用すれば業務効率化が可能となるかを具体的に考察するきっかけとなりました。\n",
            "\n",
            "### 4.3 他社事例との比較\n",
            "\n",
            "本レポートでは、サイバーエージェント内の取り組みに加えて、全社的に進められる生成AI活用事例も紹介されます。例えば：\n",
            "\n",
            "- **三菱UFJ銀行:** 生成AI「ChatGPT」を取り入れることで、ドラフト作成などのタスク自動化に成功。\n",
            "- **パナソニックコネクト:** 社内向けAIアシスタントにより、一回あたり約20分の時間短縮を実現。\n",
            "- **LINEヤフー:** GitHub Copilotの導入により、エンジニアごとの1日当たり1～2時間のコーディング効率向上。\n",
            "- **住友化学, JR西日本, 六甲バター:** それぞれ異なる業界でAI技術を活用した業務改革が具体的に評価されている事例です。\n",
            "\n",
            "これら外部事例と比較検討することで、サイバーエージェントは自社の取り組みの有効性や今後の可能性をより明確に認識しています。\n",
            "\n",
            "\n",
            "## 5. 技術基盤とインフラ整備\n",
            "\n",
            "### 5.1 技術スタックの詳細\n",
            "\n",
            "サイバーエージェントでは、業務効率化とプロダクト開発の両軸において、最新の技術スタックが採用されています。バックエンド技術としては、Python（Django Rest framework / FastAPI）、Go（Echo）、Scala（cats / zio）などのフレームワークが用いられ、フロントエンドはTypeScript（Next.js, Nuxt.js）により実装されています。これにより、柔軟で拡張性のあるシステムアーキテクチャが実現されています。\n",
            "\n",
            "### 5.2 クラウドとコンテナ技術\n",
            "\n",
            "インフラ面では、AWS（ECS, SNS, SQS, Lambda, EMR）やGoogle Kubernetes Engineを活用し、DockerやKubernetes、ArgoCDなどのコンテナ技術により、効率的なデプロイとスケーラビリティの確保に注力されています。また、オンプレミス環境における機械学習の運用に関しても、高性能GPUサーバーの管理、冷却対策、エネルギー消費の最適化が求められており、これらの物理的な課題に対する戦略も重要な研究対象となっています。\n",
            "\n",
            "\n",
            "## 6. 課題とリスク\n",
            "\n",
            "### 6.1 倫理的リスクとセキュリティ対策\n",
            "\n",
            "生成AI技術の実装には、プロンプトインジェクションや情報のハルシネーションなど、倫理的およびセキュリティ上のリスクが伴います。サイバーエージェントは、このようなリスクに対して、厳格なAI倫理ガイドラインの策定、発言内容のフィルタリング、またはガードレールの設定といった対策を講じることで、安全性の確保に努めています。\n",
            "\n",
            "### 6.2 技術進化への対応と人材育成\n",
            "\n",
            "急速に進化する生成AI技術に対応するためには、全社員のリテラシー向上が不可欠です。近年、社内コンペやeラーニングプログラムを通じて、社員が最新技術を学び、業務に即応できる環境を整備しています。しかし、組織が拡大する中で、情報共有の効率化や継続的な学習環境の整備という課題も存在し、今後の取り組みとして重視されています。\n",
            "\n",
            "### 6.3 ハードウェアおよびインフラコスト\n",
            "\n",
            "高性能なGPUサーバーの消費電力、冷却システム、さらには故障率の高さなど、物理的なインフラコストとその最適化も大きなチャレンジです。これらは、信頼性の高い生成AIプロダクトの実現と、既存のオンプレミス環境とのバランスが求められるため、効率的な運用体制の構築が急務となっています。\n",
            "\n",
            "\n",
            "## 7. 今後の展望と推奨戦略\n",
            "\n",
            "### 7.1 継続的なイノベーションと倫理的ガバナンス\n",
            "\n",
            "同社は、生成AIを中心とする革新的な技術を活用して業務プロセス改革を推進し続けるとともに、倫理的なリスク管理の徹底を図る必要があります。具体的には、AI倫理のガイドラインの定期的な更新、内部監査の強化、並びに安全なAI利用に関する社内教育の継続が求められます。\n",
            "\n",
            "### 7.2 組織内のナレッジ共有と横展開\n",
            "\n",
            "各部署間での成功事例の共有や、社内コミュニケーションの促進により、生成AI技術の効果的な活用が可能となります。特に、AIオペレーション室の役割を通じ、全社員がリアルタイムに最新の技術動向を把握し、業務効率化のアイデアを横断的に展開する取り組みは、今後さらに重要となるでしょう。\n",
            "\n",
            "### 7.3 市場との連携と産学連携の強化\n",
            "\n",
            "外部のパートナー企業や大学、研究機関との連携を強化することで、最新技術の応用例の共有や、具体的なプロジェクトの推進が加速します。これにより、技術の進化をいち早く取り入れつつ、業界全体の標準となるプロダクトやソリューションの開発が期待されます。\n",
            "\n",
            "\n",
            "## 8. 結論\n",
            "\n",
            "サイバーエージェントのAI事業本部は、AIおよび生成AI技術を活用した先進的な業務効率化の取り組みと、技術革新を両立するための堅牢な組織体制を有しています。各種AIツールの導入や自社開発プロダクトを活用することで、業務の生産性向上を実現してきました。加えて、倫理的リスクへの対応やインフラ面での課題解決に注力することで、持続可能なイノベーションを維持しようとする姿勢が窺えます。今後もさらなる技術革新と組織内のナレッジ共有、そして外部との連携を通じ、業務効率化と新規事業の創出に寄与する体制を進化させていくことが期待されます。\n",
            "\n",
            "このレポートで示した各取り組みと課題は、今後のサイバーエージェントが業界内で競争優位性を確保し、革新的なデジタル広告およびAI事業の発展に寄与するための貴重な指針となるでしょう。\n",
            "\n",
            "---\n",
            "\n",
            "## 9. 参考資料\n",
            "\n",
            "- CyberAgent公式サイトおよび各プレスリリース\n",
            "- ITmedia、Note、Wantedly、PR TIMES などのビジネス系メディアの記事\n",
            "- 外部企業の生成AI導入事例に関する複数のケーススタディ\n",
            "\n",
            "*以上、約5〜10ページにわたる詳細な検討を通じ、サイバーエージェントのAI事業本部における業務効率化のポイントと今後の展望について包括的にまとめました。*\n",
            "\n",
            "\n",
            "## 10. 今後の検討課題\n",
            "\n",
            "- 継続的な生成AIリテラシー向上策の効果測定と改善点の抽出\n",
            "- 業務効率化施策の横展開および他分野への応用可能性\n",
            "- 新たな倫理的ガイドラインの策定と、それに基づく技術の安全運用\n",
            "- 企業間・産学連携を強化し、共同研究プロジェクトを推進するための仕組み作り\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "以上が、サイバーエージェントのAI事業本部における業務効率化の取り組みについての包括的レポートです。今後のさらなる発展が期待される一方で、技術進化と共に伴う課題に対しても注意深く対処していく必要があります。\n",
            "\n",
            "\n",
            "\n",
            "=====追加質問=====\n",
            "\n",
            "\n",
            "追加質問: 生成AIの導入に際して、倫理的な問題やセキュリティリスクにどのように対処すべきか？\n",
            "社内のAIリテラシー向上施策をさらに効果的にするための具体的な手法は何か？\n",
            "他社の成功事例と比較した場合、サイバーエージェントのアプローチの強みと弱みはどこにあるのか？\n",
            "今後、技術スタックの更新やインフラ投資についてどのような戦略が考えられるか？\n"
          ]
        }
      ]
    }
  ]
}